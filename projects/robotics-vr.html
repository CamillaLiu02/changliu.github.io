<!DOCTYPE html><html lang="en" class="__variable_f367f3" style="font-family:var(--font-inter)"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/images/projects/vr-robot/i2.png" fetchPriority="high"/><link rel="preload" as="image" href="/images/projects/vr-robot/unity.png"/><link rel="preload" as="image" href="/images/projects/vr-robot/ros.jpg"/><link rel="preload" as="image" href="/images/projects/vr-robot/ur3e.png"/><link rel="stylesheet" href="/_next/static/css/955320d3b787247f.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/74fc351921f6806e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-42eae2757869a28e.js"/><script src="/_next/static/chunks/fd9d1056-22f680ceebfa3202.js" async=""></script><script src="/_next/static/chunks/117-e871f4317e6c0adf.js" async=""></script><script src="/_next/static/chunks/main-app-152d44ccc4a0f737.js" async=""></script><script src="/_next/static/chunks/66ec4792-d5d326bb8cd66a11.js" async=""></script><script src="/_next/static/chunks/521-1c761e0f621d8364.js" async=""></script><script src="/_next/static/chunks/276-b3e707e8d2de9be0.js" async=""></script><script src="/_next/static/chunks/app/layout-40bbe385b85369ea.js" async=""></script><script src="/_next/static/chunks/878-7b493a972d9bea49.js" async=""></script><script src="/_next/static/chunks/238-4eb49e7d51bbac68.js" async=""></script><script src="/_next/static/chunks/app/projects/%5Bslug%5D/page-86b9b67565b1dd0c.js" async=""></script><title>(In Progress...)Immersive VR–Robotics Control System | Chang Liu</title><meta name="description" content="Adapted and extended a VR–robotics framework for intuitive control of real-world robotic arms. Integrated Meta Quest 3, Unity, and ROS to enable immersive manipulation of a UR3e robotic arm through pose-based VR interaction."/><meta name="author" content="Chang Liu"/><meta name="keywords" content="UI Design,UX Design,Product Design,Full Stack Developer,User Research,Design Systems"/><meta name="creator" content="Chang Liu"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><meta property="og:title" content="(In Progress...)Immersive VR–Robotics Control System"/><meta property="og:description" content="Adapted and extended a VR–robotics framework for intuitive control of real-world robotic arms. Integrated Meta Quest 3, Unity, and ROS to enable immersive manipulation of a UR3e robotic arm through pose-based VR interaction."/><meta property="og:image" content="https://yourwebsite.com/images/projects/vr-robot/i2.png"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@yourusername"/><meta name="twitter:title" content="Chang Liu - Full-Stack Developer &amp; HRI Researcher"/><meta name="twitter:description" content="Portfolio showcasing full-stack development and HRI research projects"/><meta name="twitter:image" content="https://yourwebsite.com/og-image.png"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="antialiased text-gray-900"><div class="relative z-10"><nav class="sticky top-0 z-50 w-full transition-all duration-300 bg-transparent"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex justify-between items-center h-16"><a class="text-xl font-display font-bold text-gray-900 hover:text-primary-600 transition-colors" href="/">Chang Liu</a><div class="hidden md:flex items-center space-x-1"><a class="px-4 py-2 rounded-lg text-sm font-medium transition-all duration-200 text-gray-700 hover:bg-gray-100 hover:text-gray-900" href="/">Home</a><a class="px-4 py-2 rounded-lg text-sm font-medium transition-all duration-200 text-gray-700 hover:bg-gray-100 hover:text-gray-900" href="/projects">Projects</a><a class="px-4 py-2 rounded-lg text-sm font-medium transition-all duration-200 text-gray-700 hover:bg-gray-100 hover:text-gray-900" href="/about">About</a><a class="px-4 py-2 rounded-lg text-sm font-medium transition-all duration-200 text-gray-700 hover:bg-gray-100 hover:text-gray-900" href="/resume">Resume</a><a class="px-4 py-2 rounded-lg text-sm font-medium transition-all duration-200 text-gray-700 hover:bg-gray-100 hover:text-gray-900" href="/contact">Contact</a></div><button class="md:hidden p-2 rounded-lg text-gray-700 hover:bg-gray-100 transition-colors" aria-label="Toggle menu"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 20 20" aria-hidden="true" height="24" width="24" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button></div></div></nav><main class="min-h-screen"><div class="min-h-screen bg-white"><div class="bg-gray-50 border-b border-gray-200"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-4"><a class="inline-flex items-center gap-2 text-gray-600 hover:text-gray-900 transition-colors" href="/projects"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 20 20" aria-hidden="true" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M9.707 16.707a1 1 0 01-1.414 0l-6-6a1 1 0 010-1.414l6-6a1 1 0 011.414 1.414L5.414 9H17a1 1 0 110 2H5.414l4.293 4.293a1 1 0 010 1.414z" clip-rule="evenodd"></path></svg><span>Back to Projects</span></a></div></div><div class="relative w-full h-[50vh] bg-gray-100"><img alt="(In Progress...)Immersive VR–Robotics Control System" fetchPriority="high" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/projects/vr-robot/i2.png"/></div><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div class="grid grid-cols-1 lg:grid-cols-12 gap-12"><div class="lg:col-span-8"><div class="mb-8"><div class="flex flex-wrap gap-2 mb-4"><span class="px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium">VR/XR</span><span class="px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium">Robotics</span><span class="px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium">Human-Robot Interaction</span><span class="px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium">ROS</span><span class="px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium">Research</span><span class="px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium">Motion Planning</span></div><h1 class="text-4xl sm:text-5xl font-display font-bold text-gray-900 mb-4">(In Progress...)Immersive VR–Robotics Control System</h1><p class="text-xl text-gray-600 mb-6">Adapted and extended a VR–robotics framework for intuitive control of real-world robotic arms. Integrated Meta Quest 3, Unity, and ROS to enable immersive manipulation of a UR3e robotic arm through pose-based VR interaction.</p><div class="flex flex-wrap gap-6 text-sm text-gray-600"><div class="flex items-center gap-2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 20 20" aria-hidden="true" class="text-gray-400" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M6 2a1 1 0 00-1 1v1H4a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V6a2 2 0 00-2-2h-1V3a1 1 0 10-2 0v1H7V3a1 1 0 00-1-1zm0 5a1 1 0 000 2h8a1 1 0 100-2H6z" clip-rule="evenodd"></path></svg><span>October 2025</span></div><div class="flex items-center gap-2"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 20 20" aria-hidden="true" class="text-gray-400" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm1-12a1 1 0 10-2 0v4a1 1 0 00.293.707l2.828 2.829a1 1 0 101.415-1.415L11 9.586V6z" clip-rule="evenodd"></path></svg><span>8 min read</span></div><div><span class="font-medium text-gray-900">Role:</span> <!-- -->Undergraduate Researcher</div></div><div class="mt-4"><span class="font-medium text-gray-900 mr-2">Tools:</span><span class="text-gray-600">Meta Quest 3, Unity (C#), ROS (Noetic), MoveIt, Python, UR3e Robotic Arm, Inverse Kinematics, Motion Planning</span></div></div><div class="prose prose-lg max-w-none"><h2 id="overview" class="text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24">Overview</h2>
<p class="text-gray-700 leading-relaxed mb-4">This research project investigates how immersive virtual reality interfaces can lower the barrier to robotic manipulation by enabling intuitive, pose-based control of real-world robotic arms. Rather than programming joint-level commands, users interact with a virtual representation of a robot in 3D space through a Meta Quest 3 headset, specifying target poses that are automatically translated into executable motion on a physical UR3e collaborative robotic arm.</p>
<p class="text-gray-700 leading-relaxed mb-4">The project builds upon an existing VR–robotics framework originally developed for a UR10 robot. My primary contribution focused on adapting, integrating, and validating this system for a different robot platform (UR3e), addressing hardware differences, kinematics constraints, and real-world deployment challenges.</p>
<h3 id="research-context" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">Research Context</h3>
<p class="text-gray-700 leading-relaxed mb-4">This work is lead by <strong>Callie Kim</strong>, conducted within the <a class="text-primary-600 hover:text-primary-700 underline" target="_blank" rel="noopener noreferrer" href="https://peopleandrobots.wisc.edu/"><strong>People and Robots Laboratory</strong></a> at the University of Wisconsin-Madison, which focuses on human-robot interaction, collaborative manipulation, and intuitive interfaces for robotic control.</p>
<hr/>
<h2 id="problem-statement-motivation" class="text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24">Problem Statement &amp; Motivation</h2>
<p class="text-gray-700 leading-relaxed mb-4">Traditional robot programming requires technical expertise—users must understand joint angles, coordinate frames, and motion constraints. This creates a significant barrier for non-expert users who want to control robots for specific tasks.</p>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Key Research Questions:</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Can immersive VR interfaces make robotic manipulation more intuitive?</li>
<li>How do we bridge the gap between virtual interaction and physical execution?</li>
<li>What are the usability and safety tradeoffs in immersive teleoperation?</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4">By leveraging VR interaction patterns familiar from gaming and 3D modeling, this project explores whether users can effectively control complex robotic systems through spatial reasoning alone, without explicit programming knowledge.</p>
<hr/>
<h2 id="system-architecture" class="text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24">System Architecture</h2>
<h3 id="technology-stack" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">Technology Stack</h3>
<p class="text-gray-700 leading-relaxed mb-4">The system integrates three primary layers:</p>
<p class="text-gray-700 leading-relaxed mb-4"><strong>1. VR Interface Layer (Meta Quest 3 + Unity)</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Captures user hand poses and target specifications in 3D space</li>
<li>Provides real-time visual feedback of the virtual robot state</li>
<li>Communicates pose requests over network to ROS backend
<img src="/images/projects/vr-robot/unity.png" alt="Unity"/></li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>2. ROS Control Pipeline (ROS Noetic + MoveIt)</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Receives pose targets from Unity application</li>
<li>Solves inverse kinematics using MoveIt&#x27;s planning algorithms</li>
<li>Plans collision-free trajectories</li>
<li>Enforces safety constraints and workspace limits</li>
<li>Sends execution commands to physical robot
<img src="/images/projects/vr-robot/ros.jpg" alt="Unity"/></li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>3. Physical Robot Execution (UR3e Collaborative Arm)</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Executes motion plans with real-time feedback</li>
<li>Provides safety monitoring and force-torque feedback</li>
<li>Reports execution status back through the pipeline
<img src="/images/projects/vr-robot/ur3e.png" alt="Unity"/></li>
</ul>
<h3 id="system-flow" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">System Flow</h3>
<pre><code class="bg-gray-100 px-2 py-1 rounded text-sm font-mono text-primary-600">VR User Input (Meta Quest 3)
        ↓
    Unity XR Interface
        ↓
    ROS Communication Bridge
        ↓
    MoveIt Motion Planning
    (IK Solving + Trajectory Planning)
        ↓
    UR3e Robot Controller
        ↓
    Physical Robot Execution
        ↓
    Feedback Loop → VR Visualization
</code></pre>
<hr/>
<h2 id="key-technical-contributions" class="text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24">Key Technical Contributions</h2>
<h3 id="1-hardware-adaptation-ur10-ur3e" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">1. Hardware Adaptation: UR10 → UR3e</h3>
<p class="text-gray-700 leading-relaxed mb-4">The original framework was designed for a UR10 robot. Adapting to UR3e required:</p>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Kinematic Reconfiguration</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Modified URDF (robot description) files to reflect UR3e geometry</li>
<li>Recalibrated inverse kinematics solvers for different arm reach and DOF</li>
<li>Adjusted tool-center-point (TCP) offsets for end-effector configuration</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Workspace Adjustments</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Redefined workspace boundaries (UR3e has ~500mm shorter reach than UR10)</li>
<li>Updated collision models and safety constraints</li>
<li>Validated joint limits and velocity constraints</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Coordinate Frame Alignment</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Ensured consistent frame transformations between VR space and robot space</li>
<li>Debugged frame misalignments that caused pose failures</li>
<li>Implemented robust quaternion-to-Euler angle conversions</li>
</ul>
<h3 id="2-vr-to-robot-pipeline-integration" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">2. VR-to-Robot Pipeline Integration</h3>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Pose-Based Control Architecture</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Captured user hand poses from Meta Quest 3 controllers</li>
<li>Transformed VR poses into robot base frame coordinates</li>
<li>Implemented pose validation before kinematic solving</li>
<li>Added fallback strategies for unreachable poses</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Real-Time Feedback Loop</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Mirrored physical robot state back to VR visualization</li>
<li>Displayed reachability status, collision warnings, and IK failures</li>
<li>Provided haptic feedback through VR controllers for enhanced spatial awareness</li>
</ul>
<h3 id="3-motion-planning-constraint-handling" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">3. Motion Planning &amp; Constraint Handling</h3>
<p class="text-gray-700 leading-relaxed mb-4"><strong>MoveIt Integration</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Configured MoveIt&#x27;s planning scene with UR3e URDF and collision geometry</li>
<li>Integrated RRTconnect motion planner for trajectory generation</li>
<li>Implemented time-parameterization for smooth execution</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Safety &amp; Validation</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Self-collision checking to prevent impossible poses</li>
<li>Environment collision checking for static obstacles</li>
<li>Pose reachability validation before attempting IK solving</li>
<li>Timeout handling for failed planning attempts</li>
</ul>
<h3 id="4-debugging-iterative-validation" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">4. Debugging &amp; Iterative Validation</h3>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Key Challenges Encountered:</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li><strong>Inverse Kinematics Failures</strong> – Certain poses were mathematically unreachable or had multiple solutions; solved through pose validation and user feedback</li>
<li><strong>Coordinate Frame Mismatches</strong> – Virtual and physical spaces initially misaligned; debugged through frame visualization and careful transformation verification</li>
<li><strong>Orientation Ambiguity</strong> – Small changes in VR hand orientation produced large robot motions; addressed with orientation filtering and user guidance</li>
<li><strong>Network Latency</strong> – Delays between VR input and robot feedback; mitigated through predictive visualization and buffer strategies</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Testing Methodology</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Iterative hardware-in-the-loop testing</li>
<li>Systematic validation of workspace edges and constraint boundaries</li>
<li>Usability pilot tests with early user interaction</li>
<li>Safety validation through supervised testing with multiple pose types</li>
</ul>
<hr/>
<h2 id="current-work-future-directions" class="text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24">Current Work &amp; Future Directions</h2>
<h3 id="adaptation" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">Adaptation</h3>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Transitioning the VR–robotics control pipeline from UR10 to UR3e in progress</li>
<li>Refining kinematics, motion planning, and pose alignment for reliable real-world execution</li>
<li>Iteratively testing and debugging VR-to-robot consistency during integration</li>
</ul>
<h3 id="user-research-study" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">User Research Study</h3>
<p class="text-gray-700 leading-relaxed mb-4">To validate the system, I designed a comparative user study for future deployment.</p>
<h4>Participants</h4>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li><strong>n = 24</strong> (12 per condition, counterbalanced)</li>
<li><strong>Backgrounds</strong>: 50% robotics students, 50% non-technical</li>
<li><strong>VR experience</strong>: 6 novices, 12 intermediate, 6 experts</li>
</ul>
<h4>Study Design</h4>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Independent Variable</strong>: Control method (VR vs. Keyboard/Mouse)</p>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Dependent Variables</strong>:</p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Task completion time</li>
<li>Path efficiency (distance traveled)</li>
<li>Collision rate</li>
<li>NASA-TLX workload score</li>
<li>User preference (Likert scale)</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Task</strong>: Pick up a cube, navigate through a narrow gap, place it on a target platform</p>
<h4>Procedure</h4>
<ol class="list-decimal list-inside space-y-2 mb-4 text-gray-700">
<li>10-minute training with each interface</li>
<li>5 task repetitions per interface (recorded)</li>
<li>Post-task questionnaire (SUS, NASA-TLX)</li>
<li>Semi-structured interview</li>
</ol>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Current Status</strong>:</p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Recruiting volunteers to test VR interface effectiveness</li>
<li>Measuring task completion time, accuracy, and cognitive load</li>
<li>Collecting feedback on usability and spatial understanding</li>
<li>Analyzing differences between expert and novice users</li>
</ul>
<h3 id="paper-publication" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">Paper Publication</h3>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Documenting framework adaptation process and technical insights</li>
<li>Submitting to robotics/HRI conference next semester</li>
<li>Sharing lessons learned in system integration and platform migration</li>
</ul>
<h3 id="future-extensions" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">Future Extensions</h3>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li><strong>Haptic Feedback Integration</strong> – Adding force-feedback devices for proprioceptive guidance</li>
<li><strong>Multi-Robot Coordination</strong> – Extending framework to coordinate multiple robotic arms</li>
<li><strong>Task Learning</strong> – Enabling users to record and replay manipulation sequences</li>
<li><strong>Eye-Gaze Integration</strong> – Using gaze tracking for enhanced spatial targeting</li>
<li><strong>Gesture-Based Commands</strong> – Beyond pose specification, exploring natural gesture interfaces</li>
</ul>
<hr/>
<h2 id="learning-outcomes-impact" class="text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24">Learning Outcomes &amp; Impact</h2>
<p class="text-gray-700 leading-relaxed mb-4">This project provided hands-on experience with:</p>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Technical Skills</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Adapting research codebases across different hardware platforms</li>
<li>Debugging multi-layer systems integrating VR, ROS, and physical hardware</li>
<li>Understanding inverse kinematics limits, singularities, and workspace constraints</li>
<li>Implementing real-time communication between game engines and ROS</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Research &amp; Problem-Solving</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Systematic debugging of hardware-software integration issues</li>
<li>Validating technical solutions through iterative testing</li>
<li>Documenting design decisions and alternative approaches</li>
<li>Communicating technical complexity to diverse audiences</li>
</ul>
<p class="text-gray-700 leading-relaxed mb-4"><strong>Human-Centered Design</strong></p>
<ul class="list-disc list-inside space-y-2 mb-4 text-gray-700">
<li>Evaluating usability tradeoffs in immersive interfaces</li>
<li>Considering safety and user experience in system design</li>
<li>Recognizing importance of feedback loops in human-robot interaction</li>
</ul>
<h3 id="broader-significance" class="text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24">Broader Significance</h3>
<p class="text-gray-700 leading-relaxed mb-4">This work contributes to a larger vision of <strong>human-centered robotics</strong>, where technical robustness, safety, and user experience must align for real-world deployment. By lowering the technical barrier to robot control, we can expand access to robotic capabilities beyond expert operators, enabling new applications in education, manufacturing, and personal robotics.</p>
<hr/>
<h2 id="collaboration-acknowledgments" class="text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24">Collaboration &amp; Acknowledgments</h2>
<p class="text-gray-700 leading-relaxed mb-4">The original VR–robotics framework and ROS pipeline were developed by collaborating researchers. My role focused on platform adaptation, system integration, and validation—ensuring that research infrastructure designed for one robot could be reliably extended to different hardware with appropriate technical modifications.</p>
<hr/>
<h2 id="reflections" class="text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24">Reflections</h2>
<p class="text-gray-700 leading-relaxed mb-4">Building this system taught me that technical implementation is only one part of the story. Equally important is:</p>
<ol class="list-decimal list-inside space-y-2 mb-4 text-gray-700">
<li><strong>Understanding System Boundaries</strong> – Knowing why the original framework was built for UR10 helped me understand what would change with UR3e</li>
<li><strong>Embracing Iterative Validation</strong> – Perfect solutions rarely work on first try; systematic testing revealed subtle coordinate-frame issues that would have been missed otherwise</li>
<li><strong>Balancing Robustness &amp; Usability</strong> – Safety constraints sometimes conflict with intuitive interaction; finding the right balance requires user feedback</li>
<li><strong>Documentation as Design</strong> – Clear documentation of configuration choices enables future researchers to extend this work further</li>
</ol>
<p class="text-gray-700 leading-relaxed mb-4">The intersection of VR interaction and robotic control remains a rich area for research, and I&#x27;m excited to see how user studies and continued refinement can make these interfaces even more effective.</p></div><div class="my-12"><h2 class="text-2xl font-bold text-gray-900 mb-6">Project Gallery</h2><div class="grid grid-cols-2 md:grid-cols-3 gap-4"><div class="relative aspect-video rounded-lg overflow-hidden cursor-pointer group" style="opacity:0;transform:scale(0.9)"><img alt="Gallery image 1" loading="lazy" decoding="async" data-nimg="fill" class="object-cover group-hover:scale-110 transition-transform duration-300" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/projects/vr-robot/i.png"/><div class="absolute inset-0 bg-black/0 group-hover:bg-black/20 transition-colors duration-300"></div></div><div class="relative aspect-video rounded-lg overflow-hidden cursor-pointer group" style="opacity:0;transform:scale(0.9)"><img alt="Gallery image 2" loading="lazy" decoding="async" data-nimg="fill" class="object-cover group-hover:scale-110 transition-transform duration-300" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/projects/vr-robot/i1.png"/><div class="absolute inset-0 bg-black/0 group-hover:bg-black/20 transition-colors duration-300"></div></div><div class="relative aspect-video rounded-lg overflow-hidden cursor-pointer group" style="opacity:0;transform:scale(0.9)"><img alt="Gallery image 3" loading="lazy" decoding="async" data-nimg="fill" class="object-cover group-hover:scale-110 transition-transform duration-300" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/projects/vr-robot/i2.png"/><div class="absolute inset-0 bg-black/0 group-hover:bg-black/20 transition-colors duration-300"></div></div><div class="relative aspect-video rounded-lg overflow-hidden cursor-pointer group" style="opacity:0;transform:scale(0.9)"><img alt="Gallery image 4" loading="lazy" decoding="async" data-nimg="fill" class="object-cover group-hover:scale-110 transition-transform duration-300" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/projects/vr-robot/i3.png"/><div class="absolute inset-0 bg-black/0 group-hover:bg-black/20 transition-colors duration-300"></div></div><div class="relative aspect-video rounded-lg overflow-hidden cursor-pointer group" style="opacity:0;transform:scale(0.9)"><img alt="Gallery image 5" loading="lazy" decoding="async" data-nimg="fill" class="object-cover group-hover:scale-110 transition-transform duration-300" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/projects/vr-robot/i4.png"/><div class="absolute inset-0 bg-black/0 group-hover:bg-black/20 transition-colors duration-300"></div></div></div></div></div><div class="lg:col-span-4"><div class="sticky top-24"><nav class="sticky top-24 space-y-1"><h4 class="text-sm font-semibold text-gray-900 mb-4 uppercase tracking-wider">On This Page</h4><ul class="space-y-2 border-l-2 border-gray-200"><li style="padding-left:0px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Overview</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Research Context</button></li><li style="padding-left:0px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Problem Statement &amp; Motivation</button></li><li style="padding-left:0px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">System Architecture</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Technology Stack</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">System Flow</button></li><li style="padding-left:0px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Key Technical Contributions</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">1. Hardware Adaptation: UR10 → UR3e</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">2. VR-to-Robot Pipeline Integration</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">3. Motion Planning &amp; Constraint Handling</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">4. Debugging &amp; Iterative Validation</button></li><li style="padding-left:0px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Current Work &amp; Future Directions</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Adaptation</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">User Research Study</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Paper Publication</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Future Extensions</button></li><li style="padding-left:0px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Learning Outcomes &amp; Impact</button></li><li style="padding-left:12px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Broader Significance</button></li><li style="padding-left:0px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Collaboration &amp; Acknowledgments</button></li><li style="padding-left:0px"><button class="block w-full text-left py-1 px-4 text-sm border-l-2 -ml-[2px] transition-all duration-200 border-transparent text-gray-600 hover:text-gray-900 hover:border-gray-300">Reflections</button></li></ul></nav></div></div></div></div></div></main><footer class="bg-gray-50 border-t border-gray-200 mt-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12"><div class="grid grid-cols-1 md:grid-cols-3 gap-8"><div><h3 class="text-lg font-display font-bold text-gray-900 mb-4">Chang Liu</h3><p class="text-gray-600 text-sm">Full-Stack Developer &amp; HRI Researcher building robust systems and intuitive interfaces.</p></div><div><h4 class="text-sm font-semibold text-gray-900 uppercase tracking-wider mb-4">Quick Links</h4><ul class="space-y-2"><li><a class="text-gray-600 hover:text-primary-600 transition-colors text-sm" href="/projects">Projects</a></li><li><a class="text-gray-600 hover:text-primary-600 transition-colors text-sm" href="/about">About</a></li><li><a class="text-gray-600 hover:text-primary-600 transition-colors text-sm" href="/resume">Resume</a></li><li><a class="text-gray-600 hover:text-primary-600 transition-colors text-sm" href="/contact">Contact</a></li></ul></div><div><h4 class="text-sm font-semibold text-gray-900 uppercase tracking-wider mb-4">Connect</h4><div class="flex space-x-4"><a href="https://www.linkedin.com/in/chang-l-276423314" target="_blank" rel="noopener noreferrer" class="text-gray-600 hover:text-primary-600 transition-colors" aria-label="LinkedIn"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a><a href="mailto:changliu5101@gmail.com" class="text-gray-600 hover:text-primary-600 transition-colors" aria-label="Email"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"></path></svg></a></div></div></div><div class="mt-8 pt-8 border-t border-gray-200 text-center"><p class="text-sm text-gray-600">© <!-- -->2026<!-- --> Chang Liu. All rights reserved.</p></div></div></footer></div><script src="/_next/static/chunks/webpack-42eae2757869a28e.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/955320d3b787247f.css\",\"style\"]\n3:HL[\"/_next/static/css/74fc351921f6806e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[2846,[],\"\"]\n7:I[4707,[],\"\"]\n9:I[6423,[],\"\"]\na:I[5915,[\"422\",\"static/chunks/66ec4792-d5d326bb8cd66a11.js\",\"521\",\"static/chunks/521-1c761e0f621d8364.js\",\"276\",\"static/chunks/276-b3e707e8d2de9be0.js\",\"185\",\"static/chunks/app/layout-40bbe385b85369ea.js\"],\"default\"]\nb:I[2972,[\"521\",\"static/chunks/521-1c761e0f621d8364.js\",\"276\",\"static/chunks/276-b3e707e8d2de9be0.js\",\"878\",\"static/chunks/878-7b493a972d9bea49.js\",\"238\",\"static/chunks/238-4eb49e7d51bbac68.js\",\"101\",\"static/chunks/app/projects/%5Bslug%5D/page-86b9b67565b1dd0c.js\"],\"\"]\nd:I[1060,[],\"\"]\n8:[\"slug\",\"robotics-vr\",\"d\"]\ne:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L4\",null,{\"buildId\":\"k_Wis2T0r3NPdNYb90F6J\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"projects\",\"robotics-vr\"],\"initialTree\":[\"\",{\"children\":[\"projects\",{\"children\":[[\"slug\",\"robotics-vr\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"robotics-vr\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"projects\",{\"children\":[[\"slug\",\"robotics-vr\",\"d\"],{\"children\":[\"__PAGE__\",{},[[\"$L5\",\"$L6\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/74fc351921f6806e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]],null],null]},[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"$8\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/955320d3b787247f.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"__variable_f367f3\",\"style\":{\"fontFamily\":\"var(--font-inter)\"},\"children\":[\"$\",\"body\",null,{\"className\":\"antialiased text-gray-900\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative z-10\",\"children\":[[\"$\",\"$La\",null,{}],[\"$\",\"main\",null,{\"className\":\"min-h-screen\",\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}],[\"$\",\"footer\",null,{\"className\":\"bg-gray-50 border-t border-gray-200 mt-20\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-3 gap-8\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-display font-bold text-gray-900 mb-4\",\"children\":\"Chang Liu\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-sm\",\"children\":\"Full-Stack Developer \u0026 HRI Researcher building robust systems and intuitive interfaces.\"}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-semibold text-gray-900 uppercase tracking-wider mb-4\",\"children\":\"Quick Links\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-2\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$Lb\",null,{\"href\":\"/projects\",\"className\":\"text-gray-600 hover:text-primary-600 transition-colors text-sm\",\"children\":\"Projects\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$Lb\",null,{\"href\":\"/about\",\"className\":\"text-gray-600 hover:text-primary-600 transition-colors text-sm\",\"children\":\"About\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$Lb\",null,{\"href\":\"/resume\",\"className\":\"text-gray-600 hover:text-primary-600 transition-colors text-sm\",\"children\":\"Resume\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$Lb\",null,{\"href\":\"/contact\",\"className\":\"text-gray-600 hover:text-primary-600 transition-colors text-sm\",\"children\":\"Contact\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-semibold text-gray-900 uppercase tracking-wider mb-4\",\"children\":\"Connect\"}],[\"$\",\"div\",null,{\"className\":\"flex space-x-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://www.linkedin.com/in/chang-l-276423314\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-gray-600 hover:text-primary-600 transition-colors\",\"aria-label\":\"LinkedIn\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 448 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":24,\"width\":24,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}],[\"$\",\"a\",null,{\"href\":\"mailto:changliu5101@gmail.com\",\"className\":\"text-gray-600 hover:text-primary-600 transition-colors\",\"aria-label\":\"Email\",\"children\":[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 512 512\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":24,\"width\":24,\"xmlns\":\"http://www.w3.org/2000/svg\"}]}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-8 pt-8 border-t border-gray-200 text-center\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-sm text-gray-600\",\"children\":[\"© \",2026,\" Chang Liu. All rights reserved.\"]}]}]]}]}]]}]}]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$Lc\"],\"globalErrorComponent\":\"$d\",\"missingSlots\":\"$We\"}]\n"])</script><script>self.__next_f.push([1,"f:I[5878,[\"521\",\"static/chunks/521-1c761e0f621d8364.js\",\"276\",\"static/chunks/276-b3e707e8d2de9be0.js\",\"878\",\"static/chunks/878-7b493a972d9bea49.js\",\"238\",\"static/chunks/238-4eb49e7d51bbac68.js\",\"101\",\"static/chunks/app/projects/%5Bslug%5D/page-86b9b67565b1dd0c.js\"],\"Image\"]\n11:I[8121,[\"521\",\"static/chunks/521-1c761e0f621d8364.js\",\"276\",\"static/chunks/276-b3e707e8d2de9be0.js\",\"878\",\"static/chunks/878-7b493a972d9bea49.js\",\"238\",\"static/chunks/238-4eb49e7d51bbac68.js\",\"101\",\"static/chunks/app/projects/%5Bslug%5D/page-86b9b67565b1dd0c.js\"],\"default\"]\n12:I[6951,[\"521\",\"static/chunks/521-1c761e0f621d8364.js\",\"276\",\"static/chunks/276-b3e707e8d2de9be0.js\",\"878\",\"static/chunks/878-7b493a972d9bea49.js\",\"238\",\"static/chunks/238-4eb49e7d51bbac68.js\",\"101\",\"static/chunks/app/projects/%5Bslug%5D/page-86b9b67565b1dd0c.js\"],\"default\"]\n"])</script><script>self.__next_f.push([1,"6:[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-white\",\"children\":[[\"$\",\"div\",null,{\"className\":\"bg-gray-50 border-b border-gray-200\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-4\",\"children\":[\"$\",\"$Lb\",null,{\"href\":\"/projects\",\"className\":\"inline-flex items-center gap-2 text-gray-600 hover:text-gray-900 transition-colors\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 20 20\",\"aria-hidden\":\"true\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fillRule\":\"evenodd\",\"d\":\"M9.707 16.707a1 1 0 01-1.414 0l-6-6a1 1 0 010-1.414l6-6a1 1 0 011.414 1.414L5.414 9H17a1 1 0 110 2H5.414l4.293 4.293a1 1 0 010 1.414z\",\"clipRule\":\"evenodd\",\"children\":[]}]]],\"className\":\"$undefined\",\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"span\",null,{\"children\":\"Back to Projects\"}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"relative w-full h-[50vh] bg-gray-100\",\"children\":[\"$\",\"$Lf\",null,{\"src\":\"/images/projects/vr-robot/i2.png\",\"alt\":\"(In Progress...)Immersive VR–Robotics Control System\",\"fill\":true,\"className\":\"object-cover\",\"priority\":true}]}],[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12\",\"children\":[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 lg:grid-cols-12 gap-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"lg:col-span-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-4\",\"children\":[[\"$\",\"span\",\"VR/XR\",{\"className\":\"px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium\",\"children\":\"VR/XR\"}],[\"$\",\"span\",\"Robotics\",{\"className\":\"px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium\",\"children\":\"Robotics\"}],[\"$\",\"span\",\"Human-Robot Interaction\",{\"className\":\"px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium\",\"children\":\"Human-Robot Interaction\"}],[\"$\",\"span\",\"ROS\",{\"className\":\"px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium\",\"children\":\"ROS\"}],[\"$\",\"span\",\"Research\",{\"className\":\"px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium\",\"children\":\"Research\"}],[\"$\",\"span\",\"Motion Planning\",{\"className\":\"px-3 py-1 bg-primary-100 text-primary-700 rounded-full text-sm font-medium\",\"children\":\"Motion Planning\"}]]}],[\"$\",\"h1\",null,{\"className\":\"text-4xl sm:text-5xl font-display font-bold text-gray-900 mb-4\",\"children\":\"(In Progress...)Immersive VR–Robotics Control System\"}],[\"$\",\"p\",null,{\"className\":\"text-xl text-gray-600 mb-6\",\"children\":\"Adapted and extended a VR–robotics framework for intuitive control of real-world robotic arms. Integrated Meta Quest 3, Unity, and ROS to enable immersive manipulation of a UR3e robotic arm through pose-based VR interaction.\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-6 text-sm text-gray-600\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 20 20\",\"aria-hidden\":\"true\",\"className\":\"text-gray-400\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fillRule\":\"evenodd\",\"d\":\"M6 2a1 1 0 00-1 1v1H4a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V6a2 2 0 00-2-2h-1V3a1 1 0 10-2 0v1H7V3a1 1 0 00-1-1zm0 5a1 1 0 000 2h8a1 1 0 100-2H6z\",\"clipRule\":\"evenodd\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"span\",null,{\"children\":\"October 2025\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 20 20\",\"aria-hidden\":\"true\",\"className\":\"text-gray-400\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"fillRule\":\"evenodd\",\"d\":\"M10 18a8 8 0 100-16 8 8 0 000 16zm1-12a1 1 0 10-2 0v4a1 1 0 00.293.707l2.828 2.829a1 1 0 101.415-1.415L11 9.586V6z\",\"clipRule\":\"evenodd\",\"children\":[]}]]],\"style\":{\"color\":\"$undefined\"},\"height\":\"1em\",\"width\":\"1em\",\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"span\",null,{\"children\":\"8 min read\"}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-medium text-gray-900\",\"children\":\"Role:\"}],\" \",\"Undergraduate Researcher\"]}]]}],[\"$\",\"div\",null,{\"className\":\"mt-4\",\"children\":[[\"$\",\"span\",null,{\"className\":\"font-medium text-gray-900 mr-2\",\"children\":\"Tools:\"}],[\"$\",\"span\",null,{\"className\":\"text-gray-600\",\"children\":\"Meta Quest 3, Unity (C#), ROS (Noetic), MoveIt, Python, UR3e Robotic Arm, Inverse Kinematics, Motion Planning\"}]]}],\"$undefined\"]}],[\"$\",\"div\",null,{\"className\":\"prose prose-lg max-w-none\",\"children\":\"$L10\"}],[\"$\",\"$L11\",null,{\"images\":[\"/images/projects/vr-robot/i.png\",\"/images/projects/vr-robot/i1.png\",\"/images/projects/vr-robot/i2.png\",\"/images/projects/vr-robot/i3.png\",\"/images/projects/vr-robot/i4.png\"],\"title\":\"Project Gallery\"}]]}],[\"$\",\"div\",null,{\"className\":\"lg:col-span-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"sticky top-24\",\"children\":[\"$\",\"$L12\",null,{\"headings\":[{\"id\":\"overview\",\"text\":\"Overview\",\"level\":2},{\"id\":\"research-context\",\"text\":\"Research Context\",\"level\":3},{\"id\":\"problem-statement-motivation\",\"text\":\"Problem Statement \u0026 Motivation\",\"level\":2},{\"id\":\"system-architecture\",\"text\":\"System Architecture\",\"level\":2},{\"id\":\"technology-stack\",\"text\":\"Technology Stack\",\"level\":3},{\"id\":\"system-flow\",\"text\":\"System Flow\",\"level\":3},{\"id\":\"key-technical-contributions\",\"text\":\"Key Technical Contributions\",\"level\":2},{\"id\":\"1-hardware-adaptation-ur10-ur3e\",\"text\":\"1. Hardware Adaptation: UR10 → UR3e\",\"level\":3},{\"id\":\"2-vr-to-robot-pipeline-integration\",\"text\":\"2. VR-to-Robot Pipeline Integration\",\"level\":3},{\"id\":\"3-motion-planning-constraint-handling\",\"text\":\"3. Motion Planning \u0026 Constraint Handling\",\"level\":3},{\"id\":\"4-debugging-iterative-validation\",\"text\":\"4. Debugging \u0026 Iterative Validation\",\"level\":3},{\"id\":\"current-work-future-directions\",\"text\":\"Current Work \u0026 Future Directions\",\"level\":2},{\"id\":\"adaptation\",\"text\":\"Adaptation\",\"level\":3},{\"id\":\"user-research-study\",\"text\":\"User Research Study\",\"level\":3},{\"id\":\"paper-publication\",\"text\":\"Paper Publication\",\"level\":3},{\"id\":\"future-extensions\",\"text\":\"Future Extensions\",\"level\":3},{\"id\":\"learning-outcomes-impact\",\"text\":\"Learning Outcomes \u0026 Impact\",\"level\":2},{\"id\":\"broader-significance\",\"text\":\"Broader Significance\",\"level\":3},{\"id\":\"collaboration-acknowledgments\",\"text\":\"Collaboration \u0026 Acknowledgments\",\"level\":2},{\"id\":\"reflections\",\"text\":\"Reflections\",\"level\":2}]}]}]}]]}]}]]}]\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"(In Progress...)Immersive VR–Robotics Control System | Chang Liu\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Adapted and extended a VR–robotics framework for intuitive control of real-world robotic arms. Integrated Meta Quest 3, Unity, and ROS to enable immersive manipulation of a UR3e robotic arm through pose-based VR interaction.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"Chang Liu\"}],[\"$\",\"meta\",\"5\",{\"name\":\"keywords\",\"content\":\"UI Design,UX Design,Product Design,Full Stack Developer,User Research,Design Systems\"}],[\"$\",\"meta\",\"6\",{\"name\":\"creator\",\"content\":\"Chang Liu\"}],[\"$\",\"meta\",\"7\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"8\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:title\",\"content\":\"(In Progress...)Immersive VR–Robotics Control System\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:description\",\"content\":\"Adapted and extended a VR–robotics framework for intuitive control of real-world robotic arms. Integrated Meta Quest 3, Unity, and ROS to enable immersive manipulation of a UR3e robotic arm through pose-based VR interaction.\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image\",\"content\":\"https://yourwebsite.com/images/projects/vr-robot/i2.png\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:creator\",\"content\":\"@yourusername\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"Chang Liu - Full-Stack Developer \u0026 HRI Researcher\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"Portfolio showcasing full-stack development and HRI research projects\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://yourwebsite.com/og-image.png\"}],[\"$\",\"meta\",\"17\",{\"name\":\"next-size-adjust\"}]]\n5:null\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"h2\",null,{\"id\":\"overview\",\"className\":\"text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24\",\"children\":\"Overview\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"This research project investigates how immersive virtual reality interfaces can lower the barrier to robotic manipulation by enabling intuitive, pose-based control of real-world robotic arms. Rather than programming joint-level commands, users interact with a virtual representation of a robot in 3D space through a Meta Quest 3 headset, specifying target poses that are automatically translated into executable motion on a physical UR3e collaborative robotic arm.\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"The project builds upon an existing VR–robotics framework originally developed for a UR10 robot. My primary contribution focused on adapting, integrating, and validating this system for a different robot platform (UR3e), addressing hardware differences, kinematics constraints, and real-world deployment challenges.\"}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"research-context\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"Research Context\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"This work is lead by \",[\"$\",\"strong\",null,{\"children\":\"Callie Kim\"}],\", conducted within the \",[\"$\",\"a\",null,{\"className\":\"text-primary-600 hover:text-primary-700 underline\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"href\":\"https://peopleandrobots.wisc.edu/\",\"children\":[\"$\",\"strong\",null,{\"children\":\"People and Robots Laboratory\"}]}],\" at the University of Wisconsin-Madison, which focuses on human-robot interaction, collaborative manipulation, and intuitive interfaces for robotic control.\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"problem-statement-motivation\",\"className\":\"text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24\",\"children\":\"Problem Statement \u0026 Motivation\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"Traditional robot programming requires technical expertise—users must understand joint angles, coordinate frames, and motion constraints. This creates a significant barrier for non-expert users who want to control robots for specific tasks.\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Key Research Questions:\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Can immersive VR interfaces make robotic manipulation more intuitive?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"How do we bridge the gap between virtual interaction and physical execution?\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"What are the usability and safety tradeoffs in immersive teleoperation?\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"By leveraging VR interaction patterns familiar from gaming and 3D modeling, this project explores whether users can effectively control complex robotic systems through spatial reasoning alone, without explicit programming knowledge.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"system-architecture\",\"className\":\"text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24\",\"children\":\"System Architecture\"}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"technology-stack\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"Technology Stack\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"The system integrates three primary layers:\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"1. VR Interface Layer (Meta Quest 3 + Unity)\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Captures user hand poses and target specifications in 3D space\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Provides real-time visual feedback of the virtual robot state\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Communicates pose requests over network to ROS backend\\n\",[\"$\",\"img\",null,{\"src\":\"/images/projects/vr-robot/unity.png\",\"alt\":\"Unity\"}]]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"2. ROS Control Pipeline (ROS Noetic + MoveIt)\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Receives pose targets from Unity application\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Solves inverse kinematics using MoveIt's planning algorithms\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Plans collision-free trajectories\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Enforces safety constraints and workspace limits\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Sends execution commands to physical robot\\n\",[\"$\",\"img\",null,{\"src\":\"/images/projects/vr-robot/ros.jpg\",\"alt\":\"Unity\"}]]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"3. Physical Robot Execution (UR3e Collaborative Arm)\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Executes motion plans with real-time feedback\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Provides safety monitoring and force-torque feedback\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"Reports execution status back through the pipeline\\n\",[\"$\",\"img\",null,{\"src\":\"/images/projects/vr-robot/ur3e.png\",\"alt\":\"Unity\"}]]}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"system-flow\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"System Flow\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"className\":\"bg-gray-100 px-2 py-1 rounded text-sm font-mono text-primary-600\",\"children\":\"VR User Input (Meta Quest 3)\\n        ↓\\n    Unity XR Interface\\n        ↓\\n    ROS Communication Bridge\\n        ↓\\n    MoveIt Motion Planning\\n    (IK Solving + Trajectory Planning)\\n        ↓\\n    UR3e Robot Controller\\n        ↓\\n    Physical Robot Execution\\n        ↓\\n    Feedback Loop → VR Visualization\\n\"}]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"key-technical-contributions\",\"className\":\"text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24\",\"children\":\"Key Technical Contributions\"}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"1-hardware-adaptation-ur10-ur3e\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"1. Hardware Adaptation: UR10 → UR3e\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"The original framework was designed for a UR10 robot. Adapting to UR3e required:\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Kinematic Reconfiguration\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Modified URDF (robot description) files to reflect UR3e geometry\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Recalibrated inverse kinematics solvers for different arm reach and DOF\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Adjusted tool-center-point (TCP) offsets for end-effector configuration\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Workspace Adjustments\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Redefined workspace boundaries (UR3e has ~500mm shorter reach than UR10)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Updated collision models and safety constraints\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Validated joint limits and velocity constraints\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Coordinate Frame Alignment\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Ensured consistent frame transformations between VR space and robot space\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Debugged frame misalignments that caused pose failures\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Implemented robust quaternion-to-Euler angle conversions\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"2-vr-to-robot-pipeline-integration\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"2. VR-to-Robot Pipeline Integration\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Pose-Based Control Architecture\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Captured user hand poses from Meta Quest 3 controllers\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Transformed VR poses into robot base frame coordinates\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Implemented pose validation before kinematic solving\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Added fallback strategies for unreachable poses\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Real-Time Feedback Loop\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Mirrored physical robot state back to VR visualization\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Displayed reachability status, collision warnings, and IK failures\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Provided haptic feedback through VR controllers for enhanced spatial awareness\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"3-motion-planning-constraint-handling\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"3. Motion Planning \u0026 Constraint Handling\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"MoveIt Integration\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Configured MoveIt's planning scene with UR3e URDF and collision geometry\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Integrated RRTconnect motion planner for trajectory generation\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Implemented time-parameterization for smooth execution\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Safety \u0026 Validation\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Self-collision checking to prevent impossible poses\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Environment collision checking for static obstacles\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Pose reachability validation before attempting IK solving\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Timeout handling for failed planning attempts\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"4-debugging-iterative-validation\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"4. Debugging \u0026 Iterative Validation\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Key Challenges Encountered:\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Inverse Kinematics Failures\"}],\" – Certain poses were mathematically unreachable or had multiple solutions; solved through pose validation and user feedback\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Coordinate Frame Mismatches\"}],\" – Virtual and physical spaces initially misaligned; debugged through frame visualization and careful transformation verification\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Orientation Ambiguity\"}],\" – Small changes in VR hand orientation produced large robot motions; addressed with orientation filtering and user guidance\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Network Latency\"}],\" – Delays between VR input and robot feedback; mitigated through predictive visualization and buffer strategies\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Testing Methodology\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Iterative hardware-in-the-loop testing\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Systematic validation of workspace edges and constraint boundaries\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Usability pilot tests with early user interaction\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Safety validation through supervised testing with multiple pose types\"}],\"\\n\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"current-work-future-directions\",\"className\":\"text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24\",\"children\":\"Current Work \u0026 Future Directions\"}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"adaptation\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"Adaptation\"}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Transitioning the VR–robotics control pipeline from UR10 to UR3e in progress\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Refining kinematics, motion planning, and pose alignment for reliable real-world execution\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Iteratively testing and debugging VR-to-robot consistency during integration\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"user-research-study\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"User Research Study\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"To validate the system, I designed a comparative user study for future deployment.\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"Participants\"}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"n = 24\"}],\" (12 per condition, counterbalanced)\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Backgrounds\"}],\": 50% robotics students, 50% non-technical\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"VR experience\"}],\": 6 novices, 12 intermediate, 6 experts\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"Study Design\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"Independent Variable\"}],\": Control method (VR vs. Keyboard/Mouse)\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"Dependent Variables\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Task completion time\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Path efficiency (distance traveled)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Collision rate\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"NASA-TLX workload score\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"User preference (Likert scale)\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"Task\"}],\": Pick up a cube, navigate through a narrow gap, place it on a target platform\"]}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"Procedure\"}],\"\\n\",[\"$\",\"ol\",null,{\"className\":\"list-decimal list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"10-minute training with each interface\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"5 task repetitions per interface (recorded)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Post-task questionnaire (SUS, NASA-TLX)\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Semi-structured interview\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[[\"$\",\"strong\",null,{\"children\":\"Current Status\"}],\":\"]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Recruiting volunteers to test VR interface effectiveness\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Measuring task completion time, accuracy, and cognitive load\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Collecting feedback on usability and spatial understanding\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Analyzing differences between expert and novice users\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"paper-publication\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"Paper Publication\"}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Documenting framework adaptation process and technical insights\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Submitting to robotics/HRI conference next semester\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Sharing lessons learned in system integration and platform migration\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"future-extensions\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"Future Extensions\"}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Haptic Feedback Integration\"}],\" – Adding force-feedback devices for proprioceptive guidance\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Multi-Robot Coordination\"}],\" – Extending framework to coordinate multiple robotic arms\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Task Learning\"}],\" – Enabling users to record and replay manipulation sequences\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Eye-Gaze Integration\"}],\" – Using gaze tracking for enhanced spatial targeting\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Gesture-Based Commands\"}],\" – Beyond pose specification, exploring natural gesture interfaces\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"learning-outcomes-impact\",\"className\":\"text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24\",\"children\":\"Learning Outcomes \u0026 Impact\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"This project provided hands-on experience with:\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Technical Skills\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Adapting research codebases across different hardware platforms\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Debugging multi-layer systems integrating VR, ROS, and physical hardware\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Understanding inverse kinematics limits, singularities, and workspace constraints\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Implementing real-time communication between game engines and ROS\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Research \u0026 Problem-Solving\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Systematic debugging of hardware-software integration issues\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Validating technical solutions through iterative testing\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Documenting design decisions and alternative approaches\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Communicating technical complexity to diverse audiences\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"$\",\"strong\",null,{\"children\":\"Human-Centered Design\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"className\":\"list-disc list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"Evaluating usability tradeoffs in immersive interfaces\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Considering safety and user experience in system design\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"Recognizing importance of feedback loops in human-robot interaction\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"id\":\"broader-significance\",\"className\":\"text-2xl font-semibold text-gray-900 mt-8 mb-3 scroll-mt-24\",\"children\":\"Broader Significance\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":[\"This work contributes to a larger vision of \",[\"$\",\"strong\",null,{\"children\":\"human-centered robotics\"}],\", where technical robustness, safety, and user experience must align for real-world deployment. By lowering the technical barrier to robot control, we can expand access to robotic capabilities beyond expert operators, enabling new applications in education, manufacturing, and personal robotics.\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"collaboration-acknowledgments\",\"className\":\"text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24\",\"children\":\"Collaboration \u0026 Acknowledgments\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"The original VR–robotics framework and ROS pipeline were developed by collaborating researchers. My role focused on platform adaptation, system integration, and validation—ensuring that research infrastructure designed for one robot could be reliably extended to different hardware with appropriate technical modifications.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"id\":\"reflections\",\"className\":\"text-3xl font-bold text-gray-900 mt-12 mb-4 scroll-mt-24\",\"children\":\"Reflections\"}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"Building this system taught me that technical implementation is only one part of the story. Equally important is:\"}],\"\\n\",[\"$\",\"ol\",null,{\"className\":\"list-decimal list-inside space-y-2 mb-4 text-gray-700\",\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Understanding System Boundaries\"}],\" – Knowing why the original framework was built for UR10 helped me understand what would change with UR3e\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Embracing Iterative Validation\"}],\" – Perfect solutions rarely work on first try; systematic testing revealed subtle coordinate-frame issues that would have been missed otherwise\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Balancing Robustness \u0026 Usability\"}],\" – Safety constraints sometimes conflict with intuitive interaction; finding the right balance requires user feedback\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Documentation as Design\"}],\" – Clear documentation of configuration choices enables future researchers to extend this work further\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"className\":\"text-gray-700 leading-relaxed mb-4\",\"children\":\"The intersection of VR interaction and robotic control remains a rich area for research, and I'm excited to see how user studies and continued refinement can make these interfaces even more effective.\"}]]\n"])</script></body></html>